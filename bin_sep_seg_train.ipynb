{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Install required libs\n",
    "# !pip install git+https://github.com/qubvel/segmentation_models.pytorch\n",
    "# !pip install albumentations==0.4.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !sudo rm -rf /content/seg_recyclables\n",
    "# !git clone https://github.com/finani/seg_recyclables.git\n",
    "\n",
    "# import sys\n",
    "# sys.path.append('/content/seg_recyclables')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec 28 19:37:23 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.86       Driver Version: 470.86       CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   61C    P8    19W /  N/A |    747MiB /  7982MiB |     24%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1152      G   /usr/lib/xorg/Xorg                344MiB |\n",
      "|    0   N/A  N/A      1686      G   /usr/bin/gnome-shell               66MiB |\n",
      "|    0   N/A  N/A      2139      G   ...mviewer/tv_bin/TeamViewer       31MiB |\n",
      "|    0   N/A  N/A      2610      G   ...AAAAAAAAA= --shared-files       19MiB |\n",
      "|    0   N/A  N/A      4907      G   ...AAAAAAAAA= --shared-files      113MiB |\n",
      "|    0   N/A  N/A      7261      G   ...AAAAAAAAA= --shared-files      165MiB |\n",
      "+-----------------------------------------------------------------------------+\n",
      "\n",
      "Your runtime has 67.3 gigabytes of available RAM\n",
      "\n",
      "You are using a high-RAM runtime!\n",
      "\n",
      "Pytorch version: 1.10.1+cu102\n",
      "Is GPU available: True\n",
      "NVIDIA GeForce RTX 2080 with Max-Q Design\n",
      "The number of GPUs available: 1\n",
      "CPU count: 12\n",
      "Cuda version: 10.2\n",
      "Cudnn version: 7.6.5\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)\n",
    "\n",
    "print('')\n",
    "\n",
    "from psutil import virtual_memory\n",
    "ram_gb = virtual_memory().total / 1e9\n",
    "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "\n",
    "if ram_gb < 20:\n",
    "  print('Not using a high-RAM runtime')\n",
    "else:\n",
    "  print('You are using a high-RAM runtime!')\n",
    "\n",
    "print('')\n",
    "\n",
    "import os\n",
    "import torch\n",
    "print('Pytorch version: {}'.format(torch.__version__))\n",
    "print('Is GPU available: {}'.format(torch.cuda.is_available()))\n",
    "if torch.cuda.is_available():\n",
    "  print(torch.cuda.get_device_name(0))\n",
    "  print('The number of GPUs available: {}'.format(torch.cuda.device_count())) # Tesla P100-PCIE-16GB\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print('CPU count: {}'.format(os.cpu_count()))  # 8\n",
    "\n",
    "cuda = torch.version.cuda\n",
    "cudnn = torch.backends.cudnn.version()\n",
    "cudnn_major = cudnn // 1000\n",
    "cudnn = cudnn % 1000\n",
    "cudnn_minor = cudnn // 100\n",
    "cudnn_patch = cudnn % 100\n",
    "print('Cuda version: {}'.format(cuda)) # 11.1\n",
    "print('Cudnn version: {}.{}.{}'.format(cudnn_major, cudnn_minor, cudnn_patch)) # 8.0.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Binary Segmentation\n",
    "Classes =  ['Background', 'UNKNOWN', 'General trash', 'Paper', 'Paper pack', 'Metal', 'Glass', 'Plastic', 'Styrofoam', 'Plastic bag', 'Battery', 'Clothing']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import Utils\n",
    "from ModelManager import ModelManager\n",
    "from DataManager import DataManager, CustomAugmentation\n",
    "from TrainManager import TrainManager\n",
    "from InferManager import InferManager\n",
    "from LossManager import DiceLoss\n",
    "from LearningRateManager import CustomCosineAnnealingWarmUpRestarts\n",
    "\n",
    "Utils.fix_random_seed(random_seed=21)\n",
    "\n",
    "project_dir = '/home/weebee/recyclables/baseline'\n",
    "dataset_dir = os.path.join(project_dir, 'input')\n",
    "save_dir = os.path.join(project_dir, 'saved/tm_test')\n",
    "if not os.path.isdir(dataset_dir):\n",
    "    sys.exit('check dataset path!!')\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.mkdir(save_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=2.31s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done (t=0.75s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "Start training..\n",
      "num_epochs: 50\n",
      "save_dir: /home/weebee/recyclables/baseline/saved/tm_test\n",
      "file_name: best_model_target_clothing.pt\n",
      "val_every: 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: inhwan-wee (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/inhwan-wee/test/runs/azuvi82k\" target=\"_blank\">restful-monkey-69</a></strong> to <a href=\"https://wandb.ai/inhwan-wee/test\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0/50, Time: 2021-12-28 19:37:34, lr: 0.0001: 100%|██████████| 654/654 [00:49<00:00, 13.34it/s, loss=0.357, mean_loss=0.451, train_count=67]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start validation #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1: 100%|██████████| 163/163 [00:24<00:00,  6.58it/s, mIoU_all=0.921, mIoU_batch=1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation #1  Average Loss: 0.1896, mIoU_all: 0.9211\n",
      "Best performance at epoch or X0th epoch: 1\n",
      "Save model in /home/weebee/recyclables/baseline/saved/tm_test\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50, Time: 2021-12-28 19:38:48, lr: 0.0001: 100%|██████████| 654/654 [00:49<00:00, 13.20it/s, loss=0.261, mean_loss=0.3, train_count=56]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start validation #2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2: 100%|██████████| 163/163 [00:25<00:00,  6.51it/s, mIoU_all=0.603, mIoU_batch=0.497]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation #2  Average Loss: 0.1934, mIoU_all: 0.6027\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2/50, Time: 2021-12-28 19:40:03, lr: 0.0001: 100%|██████████| 654/654 [00:46<00:00, 14.10it/s, loss=0.111, mean_loss=0.241, train_count=58]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start validation #3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3: 100%|██████████| 163/163 [00:25<00:00,  6.42it/s, mIoU_all=0.6, mIoU_batch=0.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation #3  Average Loss: 0.0975, mIoU_all: 0.5997\n",
      "Best performance at epoch or X0th epoch: 3\n",
      "Save model in /home/weebee/recyclables/baseline/saved/tm_test\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3/50, Time: 2021-12-28 19:41:15, lr: 0.0001: 100%|██████████| 654/654 [00:48<00:00, 13.50it/s, loss=0.136, mean_loss=0.255, train_count=57]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start validation #4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4: 100%|██████████| 163/163 [00:25<00:00,  6.34it/s, mIoU_all=0.531, mIoU_batch=0.49]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation #4  Average Loss: 0.1857, mIoU_all: 0.5312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4/50, Time: 2021-12-28 19:42:30, lr: 0.0001: 100%|██████████| 654/654 [00:49<00:00, 13.20it/s, loss=0.102, mean_loss=0.243, train_count=59]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start validation #5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 5: 100%|██████████| 163/163 [00:25<00:00,  6.50it/s, mIoU_all=0.856, mIoU_batch=1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation #5  Average Loss: 0.0901, mIoU_all: 0.8559\n",
      "Best performance at epoch or X0th epoch: 5\n",
      "Save model in /home/weebee/recyclables/baseline/saved/tm_test\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 5/50, Time: 2021-12-28 19:43:45, lr: 0.0001: 100%|██████████| 654/654 [00:49<00:00, 13.19it/s, loss=0.209, mean_loss=0.215, train_count=65]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start validation #6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 6: 100%|██████████| 163/163 [00:24<00:00,  6.57it/s, mIoU_all=0.593, mIoU_batch=0.452]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation #6  Average Loss: 0.1984, mIoU_all: 0.5933\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 6/50, Time: 2021-12-28 19:45:00, lr: 0.0001: 100%|██████████| 654/654 [00:47<00:00, 13.68it/s, loss=0.0929, mean_loss=0.202, train_count=59]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start validation #7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 7: 100%|██████████| 163/163 [00:26<00:00,  6.26it/s, mIoU_all=0.958, mIoU_batch=1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation #7  Average Loss: 0.0725, mIoU_all: 0.9583\n",
      "Best performance at epoch or X0th epoch: 7\n",
      "Save model in /home/weebee/recyclables/baseline/saved/tm_test\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 7/50, Time: 2021-12-28 19:46:14, lr: 0.0001: 100%|██████████| 654/654 [00:52<00:00, 12.53it/s, loss=0.081, mean_loss=0.233, train_count=67]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start validation #8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 8: 100%|██████████| 163/163 [00:24<00:00,  6.68it/s, mIoU_all=0.948, mIoU_batch=1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation #8  Average Loss: 0.0838, mIoU_all: 0.9477\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 8/50, Time: 2021-12-28 19:47:31, lr: 0.0001: 100%|██████████| 654/654 [00:49<00:00, 13.34it/s, loss=0.0805, mean_loss=0.216, train_count=59]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start validation #9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 9: 100%|██████████| 163/163 [00:25<00:00,  6.39it/s, mIoU_all=0.906, mIoU_batch=1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation #9  Average Loss: 0.0775, mIoU_all: 0.9058\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 9/50, Time: 2021-12-28 19:48:46, lr: 0.0001: 100%|██████████| 654/654 [00:53<00:00, 12.25it/s, loss=0.0809, mean_loss=0.196, train_count=64]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start validation #10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 10: 100%|██████████| 163/163 [00:26<00:00,  6.11it/s, mIoU_all=0.875, mIoU_batch=1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation #10  Average Loss: 0.0674, mIoU_all: 0.8748\n",
      "Best performance at epoch or X0th epoch: 10\n",
      "Save model in /home/weebee/recyclables/baseline/saved/tm_test\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 10/50, Time: 2021-12-28 19:50:06, lr: 0.0001: 100%|██████████| 654/654 [00:48<00:00, 13.38it/s, loss=0.265, mean_loss=0.212, train_count=56]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start validation #11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 11: 100%|██████████| 163/163 [00:24<00:00,  6.60it/s, mIoU_all=0.863, mIoU_batch=1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation #11  Average Loss: 0.0584, mIoU_all: 0.8634\n",
      "Best performance at epoch or X0th epoch: 11\n",
      "Save model in /home/weebee/recyclables/baseline/saved/tm_test\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 11/50, Time: 2021-12-28 19:51:21, lr: 0.0001: 100%|██████████| 654/654 [00:52<00:00, 12.44it/s, loss=0.156, mean_loss=0.226, train_count=62]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start validation #12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 12: 100%|██████████| 163/163 [00:26<00:00,  6.19it/s, mIoU_all=0.649, mIoU_batch=1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation #12  Average Loss: 0.1018, mIoU_all: 0.6491\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 12/50, Time: 2021-12-28 19:52:40, lr: 0.0001: 100%|██████████| 654/654 [00:52<00:00, 12.48it/s, loss=0.0876, mean_loss=0.223, train_count=67]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start validation #13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 13: 100%|██████████| 163/163 [00:24<00:00,  6.63it/s, mIoU_all=0.732, mIoU_batch=0.492]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation #13  Average Loss: 0.0925, mIoU_all: 0.7325\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 13/50, Time: 2021-12-28 19:53:57, lr: 0.0001: 100%|██████████| 654/654 [00:49<00:00, 13.08it/s, loss=0.0764, mean_loss=0.227, train_count=59]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start validation #14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 14: 100%|██████████| 163/163 [00:25<00:00,  6.46it/s, mIoU_all=0.88, mIoU_batch=1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation #14  Average Loss: 0.0909, mIoU_all: 0.8798\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 14/50, Time: 2021-12-28 19:55:13, lr: 0.0001: 100%|██████████| 654/654 [00:51<00:00, 12.60it/s, loss=0.0885, mean_loss=0.241, train_count=66]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start validation #15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 15: 100%|██████████| 163/163 [00:25<00:00,  6.49it/s, mIoU_all=0.796, mIoU_batch=1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation #15  Average Loss: 0.0882, mIoU_all: 0.7965\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 15/50, Time: 2021-12-28 19:56:30, lr: 0.0001: 100%|██████████| 654/654 [00:51<00:00, 12.81it/s, loss=0.12, mean_loss=0.203, train_count=70]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start validation #16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 16: 100%|██████████| 163/163 [00:26<00:00,  6.26it/s, mIoU_all=0.827, mIoU_batch=1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation #16  Average Loss: 0.0669, mIoU_all: 0.8270\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 16/50, Time: 2021-12-28 19:57:47, lr: 0.0001: 100%|██████████| 654/654 [00:51<00:00, 12.59it/s, loss=0.26, mean_loss=0.211, train_count=68]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start validation #17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 17: 100%|██████████| 163/163 [00:25<00:00,  6.35it/s, mIoU_all=0.64, mIoU_batch=0.434]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation #17  Average Loss: 0.1469, mIoU_all: 0.6402\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 17/50, Time: 2021-12-28 19:59:05, lr: 0.0001: 100%|██████████| 654/654 [00:49<00:00, 13.09it/s, loss=0.0841, mean_loss=0.225, train_count=60]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start validation #18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 18: 100%|██████████| 163/163 [00:24<00:00,  6.54it/s, mIoU_all=0.938, mIoU_batch=0.499]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation #18  Average Loss: 0.0645, mIoU_all: 0.9383\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 18/50, Time: 2021-12-28 20:00:20, lr: 0.0001: 100%|██████████| 654/654 [00:52<00:00, 12.43it/s, loss=0.131, mean_loss=0.198, train_count=70]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start validation #19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 19: 100%|██████████| 163/163 [00:24<00:00,  6.56it/s, mIoU_all=0.857, mIoU_batch=1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation #19  Average Loss: 0.0769, mIoU_all: 0.8570\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 19/50, Time: 2021-12-28 20:01:38, lr: 0.0001: 100%|██████████| 654/654 [00:50<00:00, 12.99it/s, loss=0.0595, mean_loss=0.2, train_count=55]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start validation #20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 20: 100%|██████████| 163/163 [00:26<00:00,  6.18it/s, mIoU_all=0.677, mIoU_batch=0.498]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation #20  Average Loss: 0.0872, mIoU_all: 0.6774\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 20/50, Time: 2021-12-28 20:02:55, lr: 0.0001: 100%|██████████| 654/654 [00:53<00:00, 12.29it/s, loss=0.224, mean_loss=0.198, train_count=64]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start validation #21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 21: 100%|██████████| 163/163 [00:25<00:00,  6.46it/s, mIoU_all=0.587, mIoU_batch=1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation #21  Average Loss: 0.1205, mIoU_all: 0.5866\n",
      "Best performance at epoch or X0th epoch: 21\n",
      "Save model in /home/weebee/recyclables/baseline/saved/tm_test\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 21/50, Time: 2021-12-28 20:04:14, lr: 0.0001: 100%|██████████| 654/654 [00:49<00:00, 13.34it/s, loss=0.0813, mean_loss=0.177, train_count=58]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start validation #22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 22: 100%|██████████| 163/163 [00:25<00:00,  6.49it/s, mIoU_all=0.83, mIoU_batch=0.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation #22  Average Loss: 0.0673, mIoU_all: 0.8300\n",
      "Best performance at epoch or X0th epoch: 22\n",
      "Save model in /home/weebee/recyclables/baseline/saved/tm_test\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 22/50, Time: 2021-12-28 20:05:29, lr: 0.0001: 100%|██████████| 654/654 [00:48<00:00, 13.45it/s, loss=0.0888, mean_loss=0.197, train_count=60]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start validation #23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 23: 100%|██████████| 163/163 [00:25<00:00,  6.42it/s, mIoU_all=0.764, mIoU_batch=1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation #23  Average Loss: 0.0711, mIoU_all: 0.7636\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 23/50, Time: 2021-12-28 20:06:43, lr: 0.0001: 100%|██████████| 654/654 [00:50<00:00, 12.96it/s, loss=0.308, mean_loss=0.188, train_count=60]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start validation #24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 24: 100%|██████████| 163/163 [00:24<00:00,  6.56it/s, mIoU_all=0.933, mIoU_batch=1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation #24  Average Loss: 0.0478, mIoU_all: 0.9331\n",
      "Best performance at epoch or X0th epoch: 24\n",
      "Save model in /home/weebee/recyclables/baseline/saved/tm_test\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 24/50, Time: 2021-12-28 20:07:59, lr: 0.0001: 100%|██████████| 654/654 [00:53<00:00, 12.14it/s, loss=0.0913, mean_loss=0.21, train_count=67]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start validation #25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 25: 100%|██████████| 163/163 [00:25<00:00,  6.38it/s, mIoU_all=0.673, mIoU_batch=1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation #25  Average Loss: 0.0904, mIoU_all: 0.6733\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 25/50, Time: 2021-12-28 20:09:19, lr: 0.0001: 100%|██████████| 654/654 [00:50<00:00, 12.89it/s, loss=0.376, mean_loss=0.2, train_count=57]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start validation #26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 26: 100%|██████████| 163/163 [00:25<00:00,  6.31it/s, mIoU_all=0.551, mIoU_batch=0.496]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation #26  Average Loss: 0.1449, mIoU_all: 0.5507\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 26/50, Time: 2021-12-28 20:10:36, lr: 0.0001: 100%|██████████| 654/654 [00:54<00:00, 11.89it/s, loss=0.0803, mean_loss=0.19, train_count=69]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start validation #27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 27: 100%|██████████| 163/163 [00:25<00:00,  6.40it/s, mIoU_all=0.567, mIoU_batch=0.49]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation #27  Average Loss: 0.1074, mIoU_all: 0.5674\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 27/50, Time: 2021-12-28 20:11:56, lr: 0.0001: 100%|██████████| 654/654 [00:49<00:00, 13.28it/s, loss=0.0634, mean_loss=0.195, train_count=59]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start validation #28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 28: 100%|██████████| 163/163 [00:25<00:00,  6.36it/s, mIoU_all=0.685, mIoU_batch=1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation #28  Average Loss: 0.0917, mIoU_all: 0.6849\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 28/50, Time: 2021-12-28 20:13:12, lr: 0.0001: 100%|██████████| 654/654 [00:52<00:00, 12.45it/s, loss=0.199, mean_loss=0.194, train_count=60]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start validation #29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 29: 100%|██████████| 163/163 [00:25<00:00,  6.41it/s, mIoU_all=0.62, mIoU_batch=0.497]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation #29  Average Loss: 0.1327, mIoU_all: 0.6202\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 29/50, Time: 2021-12-28 20:14:30, lr: 0.0001: 100%|██████████| 654/654 [00:49<00:00, 13.35it/s, loss=0.0588, mean_loss=0.206, train_count=57]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start validation #30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 30: 100%|██████████| 163/163 [00:25<00:00,  6.40it/s, mIoU_all=0.77, mIoU_batch=1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation #30  Average Loss: 0.0870, mIoU_all: 0.7700\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 30/50, Time: 2021-12-28 20:15:45, lr: 0.0001: 100%|██████████| 654/654 [00:51<00:00, 12.68it/s, loss=0.109, mean_loss=0.244, train_count=68]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start validation #31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 31: 100%|██████████| 163/163 [00:25<00:00,  6.41it/s, mIoU_all=0.6, mIoU_batch=0.341]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation #31  Average Loss: 0.2348, mIoU_all: 0.5999\n",
      "Best performance at epoch or X0th epoch: 31\n",
      "Save model in /home/weebee/recyclables/baseline/saved/tm_test\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 31/50, Time: 2021-12-28 20:17:02, lr: 0.0001:  12%|█▏        | 77/654 [00:08<01:04,  8.91it/s, loss=0.218, mean_loss=0.143, train_count=10]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_282492/2941645.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;31m# Run Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mtrain_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     train_manager.run_train(\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/recyclables/baseline/seg_recyclables/TrainManager.py\u001b[0m in \u001b[0;36mrun_train\u001b[0;34m(self, model, config_dict, data_loader, val_loader, criterion, optimizer, lr_scheduler, save_dir, file_name, target_only_p)\u001b[0m\n\u001b[1;32m     76\u001b[0m                         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m                         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for class_name in Utils.get_classes()[1:]:\n",
    "    class_name = 'Clothing'\n",
    "    # Set Configures\n",
    "    # target_classes = Utils.get_classes()\n",
    "    target_classes = ['Background']\n",
    "    target_classes.append(class_name)\n",
    "\n",
    "    config_dict = {\n",
    "        'project_name': 'test',\n",
    "        'run_name': '[TM2_Mv2] ' + class_name,\n",
    "        'network': 'DeepLabV3Plus',\n",
    "        'encoder': 'resnet101',\n",
    "        'encoder_weights': 'imagenet',\n",
    "        'target_classes': target_classes,\n",
    "        'activation': None,\n",
    "        'multi_gpu': False,\n",
    "        'num_epochs': 50,\n",
    "        'batch_size': 4,\n",
    "        'learning_rate_0': 1e-4,\n",
    "        'number_worker': 8,\n",
    "        'val_every': 1,\n",
    "        'note': 'test train'\n",
    "    }\n",
    "\n",
    "    # Make Model\n",
    "    model_manager = ModelManager()\n",
    "    model = model_manager.make_deeplabv3plus_model(\n",
    "        encoder=config_dict['encoder'],\n",
    "        encoder_weights=config_dict['encoder_weights'],\n",
    "        class_number=len(target_classes),\n",
    "        activation=config_dict['activation'],\n",
    "        multi_gpu=config_dict['multi_gpu']\n",
    "    )\n",
    "\n",
    "    # Load Dataset\n",
    "    data_manager = DataManager(dataset_path=dataset_dir)\n",
    "    data_manager.assignDataLoaders(\n",
    "        batch_size=config_dict['batch_size'],\n",
    "        shuffle=True,\n",
    "        number_worker=config_dict['number_worker'],\n",
    "        drop_last=True,\n",
    "        # transform=CustomAugmentation.to_tensor_transform(),\n",
    "        # transform=CustomAugmentation.medium_transform(),\n",
    "        transform=CustomAugmentation.medium_transform_v2(),\n",
    "        target_segmentation=True,\n",
    "        target_classes=target_classes\n",
    "    )\n",
    "\n",
    "    # # path of saved best model\n",
    "    # model_path = os.path.join('/home/weebee/recyclables/baseline/saved/server_11_e50_train_1/', 'best_model_target_' + '_'.join([v.lower() for v in target_classes[1:]]) +'.pt')\n",
    "\n",
    "    # # load the saved best model\n",
    "    # checkpoint = torch.load(model_path, map_location=Utils.get_device())\n",
    "    # state_dict = checkpoint.state_dict()\n",
    "    # model.load_state_dict(state_dict)\n",
    "\n",
    "    criterion = smp.utils.losses.CrossEntropyLoss()\n",
    "    # criterion = smp.utils.losses.BCEWithLogitsLoss()\n",
    "    # criterion = tgm.losses.DiceLoss()\n",
    "    # criterion = DiceLoss()\n",
    "    # criterion = smp.utils.losses.JaccardLoss()\n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        [dict(params=model.parameters(),\n",
    "                lr=config_dict['learning_rate_0']\n",
    "                ),\n",
    "            ])\n",
    "\n",
    "    lr_scheduler = None\n",
    "    # lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    #     optimizer, max_lr=0.01, steps_per_epoch=10, epochs=epochs, anneal_strategy='cos'\n",
    "    # )\n",
    "    # lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "    #     optimizer, T_0=1, T_mult=2, eta_min=5e-5,\n",
    "    # )\n",
    "    # lr_scheduler = CustomCosineAnnealingWarmUpRestarts(\n",
    "    #     optimizer, T_0=20, T_mult=1, eta_max=0.1,  T_up=2, gamma=0.5\n",
    "    # )\n",
    "\n",
    "    # Run Train\n",
    "    train_manager = TrainManager()\n",
    "    train_manager.run_train(\n",
    "        model=model,\n",
    "        config_dict=config_dict,\n",
    "        data_loader=data_manager.train_data_loader,\n",
    "        val_loader=data_manager.val_data_loader,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        lr_scheduler=lr_scheduler,\n",
    "        save_dir=save_dir,\n",
    "        file_name='best_model_target_' + '_'.join([v.lower() for v in target_classes[1:]]) +'.pt',\n",
    "        # file_name='best_model_1.pt',\n",
    "        target_only_p=1.0 # -> 1 set = 4 batch_size\n",
    "    )\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
